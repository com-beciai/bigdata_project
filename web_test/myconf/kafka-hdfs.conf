
#flume-ng agent -n a1 -c /usr/soft/flume/conf -f /usr/soft/flume/myconf/kafka-hdfs.conf  -Dflume.root.logger=INFO,console


a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1


## sources config
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.channels =c1
a1.sources.r1.batchSize = 5000
a1.sources.r1.batchDurationMillis = 2000
#kafka 节点地址
a1.sources.r1.kafka.bootstrap.servers =192.168.88.130:9092,192.168.88.131:9092,192.168.88.132:9092
a1.sources.r1.kafka.topics = event_log
#这里需要修改
a1.sources.r1.kafka.consumer.group.id = cb1804

## channels config
a1.channels.c1.type = memory
a1.channels.c1.capacity = 100000000
a1.channels.c1.transactionCapacity = 10000000
a1.channels.c1.byteCapacityBufferPercentage = 60
a1.channels.c1.byteCapacity = 12800000000
a1.channels.c1.keep-alive = 60

#sinks config
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
#这里需要修改
a1.sinks.k1.hdfs.path = hdfs://1804-LJF:9000/logs/%Y/%m/%d
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.filePrefix = blucky_%H
a1.sinks.k1.hdfs.fileSuffix=.log
a1.sinks.k1.hdfs.minBlockReplicas=1
a1.sinks.k1.hdfs.rollInterval=60
a1.sinks.k1.hdfs.rollSize=0
a1.sinks.k1.hdfs.idleTimeout=0
a1.sinks.k1.hdfs.batchSize = 100
a1.sinks.k1.hdfs.rollCount=0
a1.sinks.k1.hdfs.useLocalTimeStamp = true

#a1.sinks.k1.channel = c1
#a1.sinks.k1.type = logger